{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones y Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicciónario para convertir los valores a categorías\n",
    "LABELS = {0: \"LowQuality\", 1: \"Average\", 2: \"HighQuality\"}\n",
    "BINS = [0, 4.5, 5.5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar ambos datasets y convertir la columna quality a categorías\n",
    "def cargar_datos(dataset):\n",
    "    ds = pd.read_csv(dataset, sep=\";\")\n",
    "    ds[\"quality_cat\"] = pd.cut(ds[\"quality\"], bins=BINS, labels=[0, 1, 2])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar(dataset):\n",
    "    # crear una nueva columna con las categorías sin modificar los valores originales\n",
    "    dataset[\"quality_cat\"] = pd.cut(dataset[\"quality\"], bins=BINS, labels=[0, 1, 2])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_x_y(df, tipo=\"regresion\"):\n",
    "    if tipo == \"categorico\":\n",
    "        x = df.drop([\"quality\", \"quality_cat\"], axis=1)\n",
    "        y = df[\"quality_cat\"]\n",
    "    else:\n",
    "        x = df.drop([\"quality\", \"quality_cat\"], axis=1)\n",
    "        y = df[\"quality\"]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar \n",
    "def normalizar(x, y):\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    y_onehot = keras.utils.to_categorical(y)\n",
    "    return x_scaled, y_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para configurar y ejecutar el modelo de clasificación\n",
    "def clasificacion(X_scaled, y_onehot, fun_act):\n",
    "    activation_fn = fun_act\n",
    "\n",
    "    # Crear el modelo de clasificación con 3 capas de 64, 32 neuronas y 1 neurona por cada clase de salida\n",
    "    classification_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation=activation_fn, input_shape=(X_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation=activation_fn),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo de clasificación con optimizador Adam, función de pérdidad Categorical Cross-Entropy, y de métrica de evaluación la exactitud\n",
    "    classification_model.compile(optimizer='adam',\n",
    "                                loss='categorical_crossentropy',\n",
    "                                metrics=['accuracy'])\n",
    "\n",
    "    # K-fold cross validation para el modelo de clasificación\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    acc = []\n",
    "    loss = []\n",
    "\n",
    "    # Entrenar el modelo de clasificación con 5-fold cross validation\n",
    "    for train_index, val_index in kf.split(X_scaled):\n",
    "        X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "        y_train, y_val = y_onehot[train_index], y_onehot[val_index]\n",
    "\n",
    "        classification_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)  # type: ignore\n",
    "\n",
    "        val_predictions = classification_model.predict(X_val)\n",
    "        val_predictions = np.argmax(val_predictions, axis=1)\n",
    "        val_true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "        acc.append(accuracy_score(val_true_labels, val_predictions))\n",
    "        loss.append(classification_model.evaluate(X_val, y_val, verbose=0)[0])  # type: ignore\n",
    "\n",
    "    print(\"\\nPrecision con función de activación \", fun_act, \": \", np.mean(acc))\n",
    "    print(\"Costo de perdida con función de activación \", fun_act, \": \", np.mean(loss))\n",
    "    return np.mean(acc), np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para configurar y ejecutar el modelo de regresión\n",
    "def regresion(X_scaled, y, fun_act):\n",
    "    activation_fn = fun_act\n",
    "\n",
    "    # Crear el modelo de regresión con 3 capas de 64, 32 neuronas y 1 neurona de salida\n",
    "    regression_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation=activation_fn, input_shape=(X_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation=activation_fn),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo de regresión con optimizador Adam, función de pérdidad Error cuadrático medio, y de métricas de evaluación el error absoluto y cuadrático medio \n",
    "    regression_model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "    # K-fold cross validation para el modelo de regresión\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    mse_scores = []\n",
    "    mae_scores = []\n",
    "\n",
    "    # Entrenar el modelo de regresión con 5-fold cross validation\n",
    "    for train_index, val_index in kf.split(X_scaled):\n",
    "        X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        regression_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0) # type: ignore\n",
    "        \n",
    "        val_predictions = regression_model.predict(X_val).flatten()\n",
    "        mse = mean_squared_error(y_val, val_predictions)\n",
    "        mae = mean_absolute_error(y_val, val_predictions)\n",
    "        mse_scores.append(mse)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    print(\"\\nMSE con función de activación \", fun_act, \": \", np.mean(mse_scores))\n",
    "    print(\"MAE con función de activación \", fun_act, \": \", np.mean(mae_scores))\n",
    "    return np.mean(mse_scores), np.mean(mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función entrega tablas comparativas con las funciones Sigmoide y Tangente hiperbólica\n",
    "def tabla_comparative(sigmoide, tanh, val1, val2):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Función de activación\": [val1, val2],\n",
    "            \"Sigmoid\": [sigmoide[0], sigmoide[1]],\n",
    "            \"Tanh\": [tanh[0], tanh[1]],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vino_blanco = cargar_datos(\"Data/winequality-white.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de clasificacion usando Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dividir_x_y(vino_blanco, \"categorico\") # regresion o categorico\n",
    "x_scaled, y_onehot = normalizar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_sigmoide = clasificacion(x_scaled, y_onehot, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_tanh = clasificacion(x_scaled, y_onehot, \"tanh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regresion usando Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dividir_x_y(vino_blanco, \"regresion\") # regresion o categorico\n",
    "x_scaled, _ = normalizar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sigmoide = regresion(x_scaled, y, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tanh = regresion(x_scaled, y, \"tanh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Classification\n",
    "\n",
    "Para el modelo de clasificación de vinos blancos, podemos ver que los resultados son dentro de todo similares, teniendo en cuenta esto, la funcion tangente hiperbólica (tanh) presenta un menor costo de pérdida a comparanción de la función sigmoidal. Lo que nos lleva a concluir que la función tangente hiperbólica sería la mas adecuada a implementar en este modelo. Se puede observar que la precisión (Accuracy) al utilizar la función tangente hiperbolica levemente mayor que la de función sigmoidal. Sin embargo, es importante considerar que esta métrica puede llegar a ser no la ideal al momento de realizar las evaluaciones ya que como sabemos gracias a los laboratorios anteriores, el dataset se encuentra desbalanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_comparative(clas_sigmoide, clas_tanh, \"Precisión\", \"Costo de perdida\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regression\n",
    "Para el modelo de regresión de vinos blancos podemos ver que los errores (cuadrático y absoluto medio), son dentro de todo similares, teniendo en cuenta esto, la funcion tangente hiperbólica (tanh) presenta errores mas pequeños a comparanción de la función sigmoidal. Lo que nos lleva a concluir que la función de activación de la tangente hiperbólica sería la mas adecuada a implementar en este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_comparative(reg_sigmoide, reg_tanh, \"MSE\", \"MAE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vino Tinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vino_tinto = cargar_datos(\"Data/winequality-red.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de clasificacion usando Red Neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dividir_x_y(vino_tinto, \"categorico\") # regresion o categorico\n",
    "x_scaled, y_onehot = normalizar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_sigmoide = clasificacion(x_scaled, y_onehot, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_tanh = clasificacion(x_scaled, y_onehot, \"tanh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regresion usando Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dividir_x_y(vino_tinto, \"regresion\") # regresion o categorico\n",
    "x_scaled, _ = normalizar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sigmoide = regresion(x_scaled, y, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tanh = regresion(x_scaled, y, \"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los Resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Classification\n",
    "Para el modelo de clasificación de vinos tintos, al igual que con los vinos blancos, la funcion tangente hiperbólica (tanh) presenta un menor costo de pérdida a comparanción de la función sigmoidal. Lo que nos lleva a concluir que la función tangente hiperbólica sería la mas adecuada a implementar en este modelo. Se puede observar que la precisión (Accuracy) al utilizar la función tangente hiperbolica levemente mayor que la de función sigmoidal. Sin embargo, es importante considerar que esta métrica puede llegar a ser no la ideal al momento de realizar las evaluaciones ya que como sabemos gracias a los laboratorios anteriores, el dataset se encuentra desbalanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_comparative(clas_sigmoide, clas_tanh, \"Precisión\", \"Costo de perdida\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regression\n",
    "Para el modelo de regresión de vinos tintos, al igual que en los vinos blancos, podemos ver que los errores (cuadrático y absoluto medio), son dentro de todo similares (esta vez mas existe menor diferencia entre ellos comparando esa diferencia entre errores de los vinos blancos). La funcion tangente hiperbólica (tanh) presenta errores mas pequeños a comparanción de la función sigmoidal. Esto nos lleva a concluir que la función de activación de la tangente hiperbólica sería la mas adecuada a implementar en este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_comparative(reg_sigmoide, reg_tanh, \"MSE\", \"MAE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
